{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "training_CNN_master.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOemIByU80Bo2eMQ/V4QWJS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JulioEI/TBCG_Group12/blob/main/training_CNN_master.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWA7ih3y-OKF"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import sys"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2brQwVG_D9Um"
      },
      "source": [
        "!git clone https://github.com/JulioEI/TBCG_Group12.git\n",
        "sys.path.insert(0,'/content/TBCG_Group12/code')\n",
        "import utils as ut\n",
        "import model_builders as mb\n",
        "import bcg_auxiliary as bcg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyERGvaHCqAE"
      },
      "source": [
        "Define General Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hs7AiXADghu"
      },
      "source": [
        "fs=1250 #sampling frequency after downsampling\n",
        "window_seconds = 0.05 #window length in seconds\n",
        "overlapping = 0.7 #window overlapping\n",
        "batch_size = 32 #batch size\n",
        "learning_rate = 1e-5 #learning rate\n",
        "epochs = 300 #number of training epochs"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnCAz0loEB4A"
      },
      "source": [
        "Select Model Type (best results with prob_NANI)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLom3HsPDl8P"
      },
      "source": [
        "binary = False #predict only binary for each window (whether there is or is not a ripple)\n",
        "Unet = False #architecture lossely based on unet\n",
        "prob_NANI = True #(by Default) predict probability for each window (gicen by the # of points inside the window which are ripples)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqEwDXd0EStY"
      },
      "source": [
        "Download training and validation data from figshare"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpvH8I5CFnxp"
      },
      "source": [
        "#TRAINING DATA\n",
        "!wget  https://figshare.com/ndownloader/articles/16856182/versions/2 -O zip_Amigo2\n",
        "!unzip /content/zip_Amigo2 -d /content/Amigo2\n",
        "!rm zip_Amigo2\n",
        "\n",
        "!wget  https://figshare.com/ndownloader/articles/16856137/versions/2 -O zip_Som2\n",
        "!unzip /content/zip_Som2 -d /content/Som2\n",
        "!rm zip_Som2\n",
        "\n",
        "#VALIDATION DATA\n",
        "!wget https://figshare.com/ndownloader/articles/14959449/versions/4 -O zip_Dlx1\n",
        "!unzip /content/zip_Dlx1 -d /content/Dlx1\n",
        "!rm zip_Dlx1\n",
        "\n",
        "!wget https://figshare.com/ndownloader/articles/14960085/versions/1 -O zip_Thy7\n",
        "!unzip /content/zip_Thy7 -d /content/Thy7\n",
        "!rm zip_Thy7"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8i4tGQtMktfP"
      },
      "source": [
        "Load training data and preprocess it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIFhhCb4-Xwv"
      },
      "source": [
        "### LOAD TRAIN DATA and PREPROCESS IT (downsampling, zscore, create windows)###\n",
        "datapath = \"/content/Amigo2\"\n",
        "data_Amigo2, ripples_tags_Amigo2, signal_Amigo2, x_train_Amigo2, y_train_Amigo2, indx_map_Amigo2 = ut.load_data_pipeline(\n",
        "    datapath, desired_fs=fs, window_seconds = window_seconds, overlapping = overlapping, zscore= True, binary = binary)\n",
        "\n",
        "datapath = \"/content/Som2\"\n",
        "data_Som2, ripples_tags_Som2, signal_Som2, x_train_Som2, y_train_Som2, indx_map_Som2 = ut.load_data_pipeline(\n",
        "    datapath, desired_fs=fs, window_seconds = window_seconds, overlapping = overlapping, zscore=True, binary = binary)\n",
        "\n",
        "### MERGE TRAINING DATA ###\n",
        "x_train = np.vstack((x_train_Amigo2, x_train_Som2))\n",
        "if binary:\n",
        "    y_train = np.vstack((y_train_Amigo2, y_train_Som2))\n",
        "else:\n",
        "    y_train = np.vstack((np.expand_dims(y_train_Amigo2,axis=1), np.expand_dims(y_train_Som2,axis=1)))\n",
        "indx_map_train = np.vstack((indx_map_Amigo2, indx_map_Som2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-XfybWPkzta"
      },
      "source": [
        "Load validation data and preprocess it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82lzlYBXFsTw"
      },
      "source": [
        "###############################################################################\n",
        "#                             VALIDATION DATA                                 #\n",
        "###############################################################################\n",
        "### LOAD VALIDATION DATA ###\n",
        "datapath = \"/content/Dlx1\"\n",
        "data_Dlx1, ripples_tags_Dlx1, signal_Dlx1, x_validation_Dlx1, y_validation_Dlx1, indx_map_Dlx1 = ut.load_data_pipeline(\n",
        "    datapath, desired_fs=fs, window_seconds = window_seconds, overlapping = overlapping, zscore=True, binary = binary)\n",
        "\n",
        "datapath = \"/content/Thy7\"\n",
        "data_Thy7, ripples_tags_Thy7, signal_Thy7, x_validation_Thy7, y_validation_Thy7, indx_map_Thy7 = ut.load_data_pipeline(\n",
        "    datapath, desired_fs=fs, window_seconds = window_seconds, overlapping = overlapping, zscore=True, binary = binary)\n",
        "\n",
        "### MERGE VALIDATION DATA ###\n",
        "x_validation = np.vstack((x_validation_Dlx1, x_validation_Thy7))\n",
        "if binary:\n",
        "    y_validation = np.vstack((y_validation_Dlx1, y_validation_Thy7))\n",
        "else:\n",
        "    y_validation = np.vstack((np.expand_dims(y_validation_Dlx1,axis=1), np.expand_dims(y_validation_Thy7,axis=1)))\n",
        "indx_map_validation = np.vstack((indx_map_Dlx1, indx_map_Thy7))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRDMco3dk1rv"
      },
      "source": [
        "Define the architecture and build the CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGKfNsGHFEtx"
      },
      "source": [
        "###############################################################################\n",
        "#                                CNN BUILDING                                 #\n",
        "###############################################################################\n",
        "\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "n_ch = data_Som2.shape[1]\n",
        "input_shape = (int(fs*window_seconds),n_ch,1)\n",
        "\n",
        "if binary:\n",
        "    model = mb.model_builder_binary(filters_Conv1 = 32, filters_Conv2 = 16, filters_Conv3=8, filters_Conv4 = 16,\n",
        "                      filters_Conv5 =16, units_Dense = 60, input_shape = input_shape,\n",
        "                      learning_rate = 1e-5)\n",
        "    !mkdir '/content/training_cp/training_binary_v1'\n",
        "    checkpoint_path = \"/content/training_cp/training_binary_v1/cp-{epoch:04d}.ckpt\"\n",
        "\n",
        "elif Unet:\n",
        "        model= mb.model_builder_Unet(filters_Conv1 = 10, filters_Conv2 = 15, filters_Conv3=15, filters_Conv4 = 15,\n",
        "                               input_shape = input_shape, learning_rate  = 1e-4)\n",
        "        !mkdir '/content/training_cp/training_unet_v1'\n",
        "        checkpoint_path = \"/content/training_cp/training_unet_v1/cp-{epoch:04d}.ckpt\"\n",
        "elif prob_NANI:\n",
        "        model = mb.model_builder_prob(filters_Conv1 = 32, filters_Conv2 = 16, filters_Conv3=8, filters_Conv4 = 16,\n",
        "                          filters_Conv5 =16, filters_Conv6=8, input_shape = input_shape, \n",
        "                          learning_rate  = 1e-5)\n",
        "        !mkdir '/content/training_cp/training_prob_vf'\n",
        "        checkpoint_path = \"/content/training_cp/training_prob_vf/cp-{epoch:04d}.ckpt\"\n",
        "\n",
        "#create checkpoint save method\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "save_freq = int(25*np.ceil(x_train.shape[0]/batch_size))\n",
        "cp_callback = ModelCheckpoint(\n",
        "    filepath=checkpoint_path, \n",
        "    verbose=1, \n",
        "    save_weights_only=True,\n",
        "    save_freq=save_freq\n",
        " )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZGpivHRk6O1"
      },
      "source": [
        "Train the CNN and save the final model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLX_Nq1R_pyS"
      },
      "source": [
        "###############################################################################\n",
        "#                                  TRAIN CNN                                  #\n",
        "###############################################################################\n",
        "model.fit(x_train,y_train, shuffle = True, epochs = epochs, batch_size = batch_size, \n",
        "          callbacks=[cp_callback], validation_data = (x_validation, y_validation))\n",
        "model.save_weights(checkpoint_path)\n",
        "# Save model\n",
        "!mkdir '/content/model'\n",
        "model.save('content/model/model_prob_vf.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1s8Ku5dk9Is"
      },
      "source": [
        "Evaluate again the final model with the validation data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K96MTZ1yilqX",
        "outputId": "6480ce67-f385-45fc-b807-e66be9188210"
      },
      "source": [
        "###############################################################################\n",
        "#                            EVALUATE CNN OUTPUT                              #\n",
        "###############################################################################\n",
        "y_prediction_Dlx1 = model.predict(x_validation_Dlx1)\n",
        "y_prediction_Thy7 = model.predict(x_validation_Thy7)\n",
        "\n",
        "events_prediction_Dlx1 = ut.get_ripple_times_from_CNN_output(y_prediction_Dlx1, \n",
        "                                     indx_map_Dlx1, th_zero = 5e-1, th_dur = 0.01, verbose = False)\n",
        "\n",
        "events_prediction_Thy7 = ut.get_ripple_times_from_CNN_output(y_prediction_Thy7,\n",
        "                                     indx_map_Thy7, th_zero = 5e-1, th_dur = 0.01, verbose = False)\n",
        "\n",
        "P_Dlx1, R_Dlx1, F1_Dlx1 = bcg.get_score(ripples_tags_Dlx1, events_prediction_Dlx1, threshold=0.1)\n",
        "print(\"Dlx1: \", P_Dlx1, R_Dlx1, F1_Dlx1)\n",
        "\n",
        "P_Thy7, R_Thy7, F1_Thy7 = bcg.get_score(ripples_tags_Thy7, events_prediction_Thy7, threshold=0.1)\n",
        "print(\"Thy7: \", P_Thy7, R_Thy7, F1_Thy7)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dlx1:  0.7149532710280374 0.7251184834123223 0.7200000000000001\n",
            "Thy7:  0.9854014598540146 0.25375939849624063 0.40358744394618834\n"
          ]
        }
      ]
    }
  ]
}